# @package training.optimizer
_target_: "torch.optim.AdamW"
lr: ${training.learning_rate}
weight_decay: ${training.weight_decay}